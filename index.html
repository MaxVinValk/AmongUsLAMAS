<!DOCTYPE html>
<html>
<head>
  <script type="text/javascript"
  src="https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js">
  </script>
  
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
body {
  margin: 0;
  font-family: Arial, Helvetica, sans-serif;
}

.top-container {
  padding: 30px;
  background-image:url('site_images/AmongUs.jpeg');
  background-repeat: no-repeat;
  background-position: center; 
  background-size: 100%;
  position: relative;
  object-fit: cover;
  width: auto;
  height: 150px;
}

.transbox {
  /* position: center; 
  width: 300px; */
  opacity: 0.8;
  height: 100px;
  margin: 30px;
  text-align: center;
  color: #ffffff;
  background-color: black;
}

/* .background {
  width:100%;
  height:auto;
}  */


.topnav {
  overflow: hidden;
  background-color: #333;
}

.topnav a {
  float: left;
  color: #f2f2f2;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 17px;
}

.topnav a:hover {
  background-color: #ddd;
  color: black;
}

.topnav a.active {
  background-color: #04AA6D;
  color: white;
}

.content {
  padding: 16px;
}

.sticky {
  position: fixed;
  top: 0;
  width: 100%;
}

.sticky + .content {
  padding-top: 102px;
}
</style>
</head>
<body>

<div class="top-container">
  <div class="transbox" >
  <h1>Among Us</h1>
  <p>Group 19: Logical Aspects of Multi-Agent Systems.</p>
  </div>
</div>

<div class="topnav" id="nav">
  <a href="#what_is_among_us">Introduction</a>
  <a href="#kripke_model">Model</a>
  <a href="#knowledge_types">Knowledge</a>
  <a href="#reasoning_rules">Rules</a>
  <a href="#findings">Findings</a>
  <a href="#technical_details">Technical Details</a>
  <a href="#extended-knowledge-model-movement-between-rooms">Extensions</a>
  <a href="https://github.com/MaxVinValk/AmongUsLAMAS">GitHub</a>
</div>

<div class="content">
  <a id="what_is_among_us"></a>
  <h2>What is Among Us?</h2>
  <p>In this game, each agent gets assigned a role: either crewmate or impostor. As a crewmate, your objective is to complete tasks to safe the ship. As an impostor, you have to prevent this from happening by killing the crewmates without anyone noticing.</p>
  <p>In short, the game exists of two phases: playing and communicating. In the first phase, all agents can walk around a map and perform several actions, such as performing a task to help the ship when you are a crewmate, or killing off a crewmate when you are an impostor. The latter, communication, phase is triggered when a crewmate finds a dead crewmate. In this phase, all agents share their last location and their knowledge about which agents are safe or not. The tricky part here is that the crewmates share this truthfully, but the impostor does not. The crewmates therefore have to figure out who is the corrupt agent by either catching them in the act of killing a crewmate, or catching them in a lie. They also have to reason with the knowledge of the other agents, but they have to watch out not to reason with the false impostor's announcements.</p>
 
  <h4>Formalizing Among Us</h4>

  <p><strong>Action Phase</strong>: The action phase consists out of two phases itself: acting and observing. In the first phase, all agents can either move to an adjacent room or perform an action, which is a task if they are crewmate, or kill if they are impostor. They can also choose to perform no action and not move. This phase is repeated until a crewmate runs into a dead body, in which case the agent can report the body at the end of the action phase. This triggers the discussion phase.<br />
    <p>The agents follow a hard-coded strategy to finish their tasks in our implementation. The discussion and voted phase is dynamic, based on what they learned during the game. The impostors move at random.</p>
    <p>To model the real game, the impostor will have a cooldown of a set number of rounds on their kill-action. When it is capable of killing a crewmate, this action is stochastic. This means that simply being in the same room as another agent without getting killed does not mean that they are a crewmate.</p>
    
    <p></p><strong>Discussion Phase</strong>: The discussion phase is started with an announcement of which agent has died and in which room. Then, each crewmate announces for every agent if they already know their role. At the start of the game, when crewmates still have not gained any knowledge, the knowledge of crewmate 1 is modelled as follows in a game with n agents: <span class="math inline">K_1 ((Imp_2 \lor \neg Imp_2) \land (Imp_3 \lor \neg Imp_3) \land ... \land (Imp_n \lor \neg Imp_n))</span>. 
    
    <p>Then, when an agent knows that for example <span class="math inline">a_2</span> is an impostor and <span class="math inline">a_3</span> is a crewmate, the knowledge gets updated to <span class="math inline">K_1 ((Imp_2) \land (\neg Imp_3) \land ... \land (Imp_n \lor \neg Imp_n))</span>.</p>
    
    <p>Impostors do not announce anything at this stage. Since crewmates only incorporate the knowledge of other agents that they are sure of are also crewmates, the announcements of the impostors would always be ignored and are therefore not of any added value. </p>

    <p></p><strong>Voting Phase</strong>: The crewmates and the impostors have different voting behaviour. Before voting, the crewmates check in the Kripke Model which worlds they still consider to be possible, and therefore also which agents they still suspect. They also check if they are already sure whether an agent is the impostor. If this latter is the case, then they will vote for this agent which they know is the impostor. Otherwise, they randomly vote for an agent which is still on their suspect-list, or they pass. When the list of suspects becomes smaller, so does the chance of crewmates passing. This allows crewmates to be more confident in their guess if there are fewer impostor possibilities. The threshold under which an agent passes is determined by the number of suspects divided by half of the initial agents.         

    <p>The impostors use higher-order knowledge in their voting strategy. Before voting, they determine which crewmate they should vote off by counting the number of suspects these crewmates still have. This number is indirectly announced in the announcement phase, and from this information impostors know what crewmates know. In order to eliminate the highest threats, the impostors vote for the agent that suspects the least number of agents and is therefore closest to finding the impostors. The impostors never vote for fellow impostors.</p>
    
    <p>After all votes have been cast, the action with most votes is executed. This means that either an agent is voted off the ship, or the voting round is passed. In case a tie occurs between multiple actions, the voting round also passes. There does not need to be a majority (e.g. more than half of the votes) for an action to be executed.</p>

    
    <p></p><p></p><strong>Ending conditions</strong>:The game can end in three possible ways:</p>
  <ul>
  <li><p>The impostors are voted out, meaning that the crewmates win.</p></li>
  <li><p>All crewmates completed all of their assigned tasks, meaning that the crewmates win.</p></li>
  <li><p>An equal number of crewmates and impostors are alive, meaning that the impostors win. In such a situation, the crewmates are not capable of voting of the impostors anymore, assuming that the impostors do not vote for other impostors.</p></li>
  </ul>

  <a id="kripke_model"></a>
  <h2>Kripke Model</h2>
  <p> Our implementation of Among Us can run for either one or two impostor(s). The size of the Kripke Model is also dependent on that. For one impostor, the model has the same number of worlds as there are agents, where each world represents a state where one agent is the impostor. For two impostors, the size of the model is the number of agents times the number of agents minus one, divided by two. In the case of ten agents, this means that there are <span class="math inline">(10*9)/2=45</span> possible worlds. This way, all possible combinations of agents have a single world. This means that <span class="math inline">w_1_2</span> does exist but <span class="math inline">w_2_1</span> does not. As for the relations, for each agent, each world in which that agent is not involved (45-9=36) is connected to all other worlds minus itself (35). Additionally, each world has a reflexive relation to itself. There are therefore <span class="math inline">(36*35)+45=1305</span> relations per agents, so <span class="math inline">10*1305=13050</span> relations in total. At the start of the game, the Kripke Model for ten agents and two impostors looks as follows:</p>
    <img src="site_images/KMFULL.png" alt="Kripke Model" style="width:auto;height:600px;">

  <p>In the visualization of the world, the reflexive arrows have been left out and the straight lines represent bidirectional arrows. Additionally, the impostor relations have also been left out of the in-game simulation. This is because the impostors do not update these relations, nor are they used by any other agents. This allows for a neater visualisation, as otherwise all relations would still be visible by at the end of the game. At the end of an example run, the Kripke Model then looks like:</p>
      
  <img src="site_images/KMEnd.png" alt="Kripke Model" style="width:auto;height:600px;">

  <a id="knowledge_types"></a>
  <h2>Knowledge Types</h2>
  <p>There are four basic types of knowledge that can be learned. Here, a<sub>1</sub> and a<sub>2</sub> $\in$ set of agents A, x<sub>1</sub> and x<sub>2</sub>$\in$ set of rooms X and y $\in$ set of timesteps Y. These are types of knowledge that can be gained by any crewmate while in the action-phase:</p>
  <ul>
    <li>Whether an agent performed a visual task. For example, a<sub>1</sub> performed a visual task in room x<sub>1</sub> at time y.</li>
    <li>Whether an impostor killed a crewmate. For example, a<sub>1</sub> was killed by <sub>2</sub> in room x<sub>1</sub> at time y.</li>
    <li>Whether an agent is dead or alive. For example, a<sub>1</sub> is alive at time y.</li>
    <li>Whether an agent is an impostor or a crewmate. For example, a<sub>1</sub> is an impostor.</li>
    </ul>
  <p>For the first two in these types of knowledge to be gained, it is important that a crewmate a<sub>1</sub> is in the same room as agent a<sub>2</sub> (where a<sub>1</sub> <span>&#8800;</span>
     a<sub>2</sub>) at the same time. The last knowledge type about whether an agent is an impostor or not can be derived from the first three knowledge types as described in the next sections.</p>
  
  <a id="reasoning_rules"></a>
  <h2>Reasoning Rules</h2>
  <p>There are several rules a crewmate (here a<sub>1</sub>) can use to deduct this last type of knowledge about who the impostors are. They are listed as follows:</p>
  <ul>
      <li>Catching the impostor in the act: (a<sub>1</sub> is in the same room x<sub>1</sub> as a<sub>2</sub> at step y $\land$ a<sub>3</sub> is dead) $\rightarrow$ a<sub>1</sub> knows a<sub>2</sub> is the impostor.</li>
    
      <li>Clearing a crewmate by seeing their task: (a<sub>1</sub> is in the same room x<sub>1</sub> as a<sub>2</sub> at step y $\land$ a<sub>2</sub> performed a visual task in room x<sub>1</sub> at step y) $\rightarrow$ a<sub>1</sub> knows a<sub>2</sub> is a crewmate.</li>
  
      <li>Dead agents must be crewmates: a<sub>1</sub> is dead $\rightarrow$ all a know that a<sub>1</sub> a crewmate.</li>
   
      <li>Trust friendly announcement: a<sub>1</sub> knows that a<sub>2</sub> is a crewmate, and a<sub>2</sub> announces that theuy know a<sub>3</sub> is a crewmate and a<sub>4</sub> is an impostor. Because of higher order knowledge, a<sub>1</sub> now also knows that a<sub>3</sub> is a crewmate and a<sub>4</sub> is an impostor.</li>

      </ul>

  <a id="findings"></a>
  <h2>Findings</h2>

  <a id="technical_details"></a>
  <h2>Techincal Details</h2>
<p>Our code can be found in this repository: <a href="https://github.com/MaxVinValk/AmongUsLAMAS">https://github.com/MaxVinValk/AmongUsLAMAS</a>. We have implemented the game mechanics and a gui in PyGame and the Kripke Model is based on <a href="https://github.com/erohkohl/mlsolver">https://github.com/erohkohl/mlsolver</a>. </p>

<a id="extended-knowledge-model-movement-between-rooms"></a>
<h2>Extended Knowledge Model: Movement between Rooms</h2>

<p>In the basic knowledge model, when a crewmate learns someone was in a room he will take this into consideration, but will not use the movement rules to infer where that person could be in the previous or next step. This information is often relevant, for example when <span class="math inline">a_1</span> sees <span class="math inline">a_2</span> at the left of the map, and in the next time step <span class="math inline">a_3</span> is killed at the right end of the map, this means <span class="math inline">a_1</span> can infer that <span class="math inline">a_2</span> cannot be the killer because he cannot have traveled across the map that quickly. We have thought about ways to extend our approach to make this kind of inference possible, which we might implement and compare if we have the time.</p>
<p>It is not feasible to construct a single Kripke model encoding the location of all agents at all time steps due to the curse of dimensionality. An alternative is to construct a set of disconnected models representing knowledge about subsets of the propositions about the game world. A reasonable simplification might be to construct one Kripke model for every combination of time step and agent (so for example in a game with 5 agents where 10 time steps have passed, there would be 50 such models). The location model for agent <span class="math inline">a_i</span> at time <span class="math inline">t</span> will be denoted <span class="math inline">M^\mathsf{loc}_{a_i,t}</span> and has the following propositional atoms:</p>
<p><span class="math display">P^\mathsf{loc}_{a_i,t} = \{\mathsf{room}_{a_i;r;t} | r \in R\} \cup \{ \mathsf{imp}_a | a \in A\},</span> where <span class="math inline">\mathsf{room}_{a_i;r;t}</span> indicates <em><span class="math inline">a_i</span> was in room <span class="math inline">r</span> at time <span class="math inline">t</span></em> and <span class="math inline">\mathsf{imp}_a</span> indicates <em>agent <span class="math inline">a</span> is the impostor</em>.</p>
<p>We know that there is exactly one impostor in the game and that an agent is in one room at any time. Therefore, the states in a location model consist of one <span class="math inline">\mathsf{room}</span> proposition and one <span class="math inline">\mathsf{imp}</span> proposition. Initially, accessibility relations are those for a distributed system (agents know their own location and impostor status, but not those of others). So initially, it holds that <span class="math inline">i \neq j \Leftrightarrow M^\mathsf{loc}_{a,t} \vDash \neg K_i \mathsf{imp}_j \land \neg K_i \neg \mathsf{imp}_j</span> unless <span class="math inline">a_i</span> is the impostor (which means he knows the impostor status of all agents).</p>
<p>Now the types of knowledge obtained by the agents during the game can be translated into announcements for the location models. This will restrict the accessibility relations, and at some point some agents may acquire knowledge that someone is or is not the impostor and use this to inform their voting. A sketch of how these announcements could work is the following (announcements are made only to the agent that learn that information, which we could model with an epistemic action model):</p>
<ul>
<li><p><em>Learning agent <span class="math inline">a</span> is in room <span class="math inline">r</span> at time <span class="math inline">t</span>:</em> In the location model <span class="math inline">M^\mathsf{loc}_{a,t}</span> this is translated as the announcement of proposition <span class="math inline">\mathsf{room}_{a;r;t}</span>. We can also translate this announcement to other time steps, by using the connectivity between the rooms. For example we know that in the previous time step, agent <span class="math inline">a</span> was in a room from which <span class="math inline">r</span> was reachable, so in model <span class="math inline">M^\mathsf{loc}_{a,t-1}</span> we can announce for all rooms <span class="math inline">r^\prime</span> that are not connected to <span class="math inline">r</span> that <span class="math inline">\neg\mathsf{room}_{a;r^\prime;t-1}</span> (meaning agent <span class="math inline">a</span> was certainly not in any of those rooms). In this way the observation can be translated to the location models of agent <span class="math inline">a</span> for all time steps.</p></li>
<li><p><em>In the discussion phase, an agent <span class="math inline">a</span> announces the location of an agent at some time:</em> We can exclude all states that contradict the announced location and where <span class="math inline">a</span> is not the impostor (because only the impostor can lie). We can again use the connectivity to translate this announcement to other time steps.</p></li>
<li><p><em>Visual task is observed of some agent <span class="math inline">a</span>:</em> We can announce to the observing agent that <span class="math inline">\neg \mathsf{imp}_a</span>.</p></li>
</ul>
<p>This needs to be worked out more carefully, but it would be interesting to see how much of an advantage the agents would get by adding this type of reasoning. The combined size of the models is much larger than the basic knowledge model, but seems like it should be manageable if implemented efficiently. If we choose to implement it this model can also easily be extended for the <em>venting</em> mechanic where the impostor can take shortcuts, to allow crewmates to notice the impostor moved too quickly.</p>
<p>It would be interesting to know if there is a more elegant way to deal with this kind of knowledge that creating a set of separate Kripke models.</p>
</div>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
   extensions: ["jsMath2jax.js"]
 });
</script>

<script
 src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>


<script>

// The function actually applying the offset
function offsetAnchor() {
    if(location.hash.length !== 0) {
        window.scrollTo(window.scrollX, window.scrollY - 65);
    }
}

// This will capture hash changes while on the page
window.addEventListener("hashchange", offsetAnchor);

// This is here so that when you enter the page with a hash,
// it can provide the offset in that case too. Having a timeout
// seems necessary to allow the browser to jump to the anchor first.
window.setTimeout(offsetAnchor, 1); // The delay of 1 is arbitrary and may not always work right (although it did in my testing).

window.onscroll = function() {myFunction()};

var header = document.getElementById("nav");
var sticky = header.offsetTop;

function myFunction() {
  if (window.pageYOffset > sticky) {
    header.classList.add("sticky");
  } else {
    header.classList.remove("sticky");
  }
}

function openCity(cityName,elmnt,color) {
  var i, tabcontent, tablinks;
  tabcontent = document.getElementsByClassName("tabcontent");
  for (i = 0; i < tabcontent.length; i++) {
    tabcontent[i].style.display = "none";
  }
  tablinks = document.getElementsByClassName("tablink");
  for (i = 0; i < tablinks.length; i++) {
    tablinks[i].style.backgroundColor = "";
  }
  document.getElementById(cityName).style.display = "block";
  elmnt.style.backgroundColor = color;

}
// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>

</body>
</html>

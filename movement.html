<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Group 19: Barbera de Mol (s3374610) Jeroen Muller (s2590182) Max Valk (s3246922)" />
  <title>Among Us: Modelling movement in Among Us with epistemic logic</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <script src="/usr/share/javascript/mathjax/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Among Us: Modelling movement in Among Us with epistemic logic</h1>
<p class="author">Group 19:<br />
<em>Barbera de Mol (s3374610</em>)<br />
<em>Jeroen Muller (s2590182)</em><br />
<em>Max Valk (s3246922)</em></p>
</header>
<h1 id="background" class="unnumbered">Background</h1>
<p>One kind of reasoning about the game Among Us involves the way players move from room to room. For example, consider a scenario where player <span class="math inline">\(c\)</span> learns that <span class="math inline">\(b\)</span> was killed in a specific room and tries to figure out who could have been the killer. He might for example think as follows: <em>“I was close to player <span class="math inline">\(a\)</span> while <span class="math inline">\(b\)</span> was killed at the other side of the map. This means <span class="math inline">\(a\)</span> cannot be the killer.”</em> A good player does not just consider the information that he observed directly, but also what can be extrapolated from it by considering the rules of the game. For example, <span class="math inline">\(a\)</span> might have been out of sight of <span class="math inline">\(c\)</span> for a short time, but <span class="math inline">\(c\)</span> can use his knowledge of the map to deduce that there was insufficient time for <span class="math inline">\(a\)</span> to move all the way to the place where <span class="math inline">\(b\)</span> was killed. In this case <span class="math inline">\(c\)</span> should still remove <span class="math inline">\(a\)</span> from his list of suspects.</p>
<p>We can capture this kind of reasoning by constructing a Kripke model that describes what agents know about where everyone is at any time. To keep things simple we will study a highly simplified version of the game in which we only consider the way agents move from room to room. Movement and observations will be described by using Dynamic Epistemic Logic action models <span class="citation" data-cites="Ditmarsch2007DynamicEL">(Ditmarsch, Hoek, and Kooi 2007)</span> with postconditions<span class="citation" data-cites="postconditions">(Benevides and Lima 2017)</span>. This approach could in principle be extended to a more complex model, where we also consider things like other types of actions and agent roles, although in that case the number of states would probably become very large even when considering modest numbers of agents and rooms. In what follows we will first describe the Kripke model and the action models used to update it. We will then describe how the model was implemented in Python, describe two optimizations that are used in the implementation, and show its application to a simple example. Our source code is available on Github and can also be executed interactively using a web-based notebook on Binder without the need to install any software.</p>
<h1 id="kripke-model" class="unnumbered">Kripke model</h1>
<p>Let <span class="math inline">\(\mathcal{A}\)</span> denote the set of agents and <span class="math inline">\(\mathcal{R}\)</span> the set of rooms. At any time, each agent is in one of a fixed set of rooms. We describe the location of agents with the set of atomic propositions <span class="math inline">\(P_{\mathcal{M},\mathcal{R}} = \{a_r | a \in \mathcal{A}, r \in \mathcal{R}\}\)</span>, where <span class="math inline">\(a_r\)</span> denotes that <span class="math inline">\(a\)</span> is in room <span class="math inline">\(r\)</span>. The way agents can move from room to room is described by the relation <span class="math inline">\(\rightsquigarrow\)</span> on the rooms, such that <span class="math inline">\(r_1 \rightsquigarrow r_2\)</span> if room <span class="math inline">\(r_2\)</span> can be reached from room <span class="math inline">\(r_1\)</span> in one movement step. Since we will always allow agents to move in both directions between rooms and to remain in the same room, the relation <span class="math inline">\(\rightsquigarrow\)</span> will be reflexive and symmetric.</p>
<p>When <span class="math inline">\(|\mathcal{A}| = m\)</span>, at any given time the knowledge in our model is described by a <span class="math inline">\(\mathcal{S}5_{\mathsf{(m)}}\)</span>-world <span class="math inline">\((\mathbb{M}, s)\)</span>, where <span class="math inline">\(\mathbb{M} = \left&lt;S, \pi, R_1, \dots, R_m \right&gt;\)</span> is a Kripke structure and the distinguished state <span class="math inline">\(s \in S\)</span> describes the real world. The valuation function <span class="math inline">\(\pi: S \rightarrow (P_{\mathcal{M},\mathcal{R}} \rightarrow \{\mathbf{t},\mathbf{f}\})\)</span> assigns a truth value to all atomic propositions in each state. Because agents are always in exactly one room, the valuation function must satisfy the following constraint for every <span class="math inline">\(a \in \mathcal{A}\)</span> in order to describe a consistent state of the game:</p>
<p><span class="math display">\[[\pi(s)(a_i) = \mathbf{t}] \quad \mathrm{iff} \quad [\pi(s)(a_j) = \mathbf{f}] (j \neq i)\]</span></p>
<h1 id="action-models" class="unnumbered">Action models</h1>
<p>The Kripke model is updated by executing an action model with preconditions and postconditions. An action model describes a set of possible actions, of which one will be executed. The definitions we use are similar to those given in <span class="citation" data-cites="postconditions">(Benevides and Lima 2017)</span>, but the preconditions are restricted to being conjunctions of possibly negated atomic propositions, which is sufficient for our prupose. Briefly, an action model with postconditions is very similar to a Kripke structure and has the following structure: <span class="math inline">\(\mathsf{M} = \left&lt;\mathsf{S}, \mathsf{pre}, \mathsf{pos}, R_1, \dots, R_m\right&gt;\)</span>. Here <span class="math inline">\(\mathsf{S}\)</span> is the set of actions that are possible in the action model. <span class="math inline">\(\mathsf{pre} : \mathsf{S} \rightarrow \mathcal{L}\)</span> assigns a precondition sentence to each action (something like <span class="math inline">\(p_1 \land p_2 \land \neg p_3\)</span>), and <span class="math inline">\(\mathsf{post} : \mathsf{S} \rightarrow (\{p_1, \dots\ p_j \}, \{\neg q_1, \dots, \neg q_k\})\)</span> assigns to each state a set of propositions that will become <em>true</em> after the corresponding action is executed and a set of propositions that will become <em>false</em>. The relations <span class="math inline">\(R_m\)</span> relate states that are indistinguishable for agent <span class="math inline">\(m\)</span>.</p>
<p>The result of executing an action <span class="math inline">\((\mathsf{M}, \mathsf{j})\)</span> in action model <span class="math inline">\((\mathbb{M}, s)\)</span> is the Kripke world (<span class="math inline">\(\mathbb{M} \otimes \mathsf{M}, (s, \mathsf{j}))\)</span>. We will not repeat the definition of the operation, but the states <span class="math inline">\((s, \mathsf{j})\)</span> of <span class="math inline">\(\mathbb{M} \otimes \mathsf{M}\)</span> are those states in the Caresian product <span class="math inline">\(S \times \mathsf{S}\)</span> where <span class="math inline">\((mathbb{M}, s) \vDash pre(\mathsf{j})\)</span>, with the substitutions in the postcondition carried out. Two states in the product model are related for agend <span class="math inline">\(a\)</span> if the corresponding states and actions are related for that agent in <em>both</em> the Kripke model and the action model (thus agents can distinguish resulting states when they can distinguish either the previous state or the action).</p>
<p>In our simplified version of Among Us, every turn consists of all agents simulataneously taking a movement step, followed by them simultaneously observing the state of the new room they are in. We can neatly define this set of operations as the execution of a set of action models. We will define a movement action model <span class="math inline">\(\mathsf{MOV}_a\)</span> describing agent <span class="math inline">\(a\)</span> taking one step, and an action model <span class="math inline">\(\mathsf{OBS}\)</span> for the effect of all observations. The relation between the Kripke models of two consecutive time steps is then as follows:</p>
<p><span class="math display">\[(\mathbb{M}_{t+1}, s_{t+1}) = (\mathbb{M}_{t}, s_{t}) \otimes (\mathsf{MOV}_{a}, \mathsf{mov}_{a,t}) \otimes \dots \otimes (\mathsf{MOV}_{m}, \mathsf{mov}_{m,t}) \otimes (\mathsf{OBS}, \mathsf{obs}_{t})\]</span></p>
<h2 id="single-agent-movement" class="unnumbered">Single agent movement</h2>
<p>The single agent movement action model <span class="math inline">\(\mathsf{MOV_a}\)</span> contains one state for every connected pair of rooms <span class="math inline">\((r, s) \in \rightsquigarrow\)</span>. It has precondition <span class="math inline">\(\mathsf{pre}(r,s) = a_r\)</span>, and postcondition <span class="math inline">\(\mathsf{post}(r,s) (\{a_s\}, \{\neg a_r\})\)</span> (so the only change is the position of agent <span class="math inline">\(a\)</span>). All states are distinguishable for <span class="math inline">\(a\)</span> and indistinguishable for all other agents, so <span class="math inline">\(R_x\)</span> includes only the reflexive relations if <span class="math inline">\(x=a\)</span> and is the full relation on the states of <span class="math inline">\(\mathsf{MOV_a}\)</span> for all other agents.</p>
<h2 id="observation" class="unnumbered">Observation</h2>
<p>The observation action model contains one action for every possible distribution of agents over rooms, so the total number of states is <span class="math inline">\(|\mathcal{R}| ^ {|\mathcal{A}|}\)</span>. For the state for a distribution <span class="math inline">\((a_i, b_j, \dots)\)</span>, the precondition will be the conjunction <span class="math inline">\(a_i \land b_j \land \dots\)</span>, so each action picks out states in the Kripke model that match that distribution of agents. Two states in the observation action model are equivalent for agent <span class="math inline">\(a\)</span> if the set of agents in the room where <span class="math inline">\(a\)</span> is is the same. The postconditions of the observation action model is empty. Thus, applying this action model leaves the size of the Kripke model unchanged but removes relations where agents can distinguish the corresponding states based on what they can see in the room they are in.</p>
<h1 id="implementation" class="unnumbered">Implementation</h1>
<p>The Kripke models and action models were implemented from scratch in Python using the <code>NetworkX</code> graph manipulation library<span class="citation" data-cites="NetworkX">(Hagberg, Schult, and Swart 2008)</span>. As we only consider fairly simple sentences here, all logical sentences are evaluated using the built-in set operations of Python. To be able to handle more complex sentences (like higher-order knowledge) the Kripke models could be translated into <code>mlsolver</code> models like the other part of our project, but for the sake of simplicity we did not pursue this.</p>
<h2 id="optimization-1-removing-irrelevant-states" class="unnumbered">Optimization 1: Removing irrelevant states</h2>
<p>Because we only evaluate sentences that contain a single <span class="math inline">\(K_a\)</span>-operator in the distinguished state <span class="math inline">\(s\)</span> and this operator only depends on the states that are reachable from <span class="math inline">\(s\)</span> in one step, the ourcomes we report do not depend on the states in the Kripke-model that are not related to <span class="math inline">\(s\)</span> for any agent. We can use this fact by removing all states that are not neighbours of <span class="math inline">\(s\)</span> after every application of an action model. It is easy to see that this simplification is safe as long as the preconditions and postconditions in the action model don’t use the <span class="math inline">\(K\)</span>-operator (which is currently not possible in our simulation). This optimization can be enabled or disabled in the simulation, and was used during the generation of the results below.</p>
<h2 id="optimization-2-replacing-nodes-with-their-bisimulation-class" class="unnumbered">Optimization 2: Replacing nodes with their bisimulation class</h2>
<p>After the execution of a sequence of action models, one state will be created for each sequence of actions that is allowed by the preconditions. This means the number of states tends to grow as the simulation proceeds. Many of these states can be removed by the first optimization, but an orthagonal problem is the creation of states that are equivalent for the evaluation of all sentences. This type of equivalence is called a bisimulation, and we can deal with it by replacing all states in the Kripke-model with their bisimulation class. A full explanation is given in <span class="citation" data-cites="Bisimulations">(Eijck 2006)</span>, in addition to an algorithm that can be used to perform the optimization. We implemented this algorithm and saw a simplification of the Kripke model in many cases. For example, when the simulation is started with two agent in the same room that are then moved apart and back together, both agents know the full state of the game, but the Kripke model will consist of a number of indistinguishable states referring to each other. The application of the bisimulation algorithm correctly reduces these to a single state. In our example below, this step was performed after the removal of irrelevant sates every time an action model was executed. In the implementation of the bisimulation algorithm an existing recipe for partitioning sets into equivalence classes based on a binary predicate was used <span class="citation" data-cites="partition">(Reid 2007)</span> together with the graph algorithms built into <code>NetworX</code>.</p>
<h1 id="example" class="unnumbered">Example</h1>
<p>For the example, we consider a game where two agents <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are moving around in a map of four room that are connected in a linear fashion (<span class="math inline">\(r_1 \leftrightsquigarrow  r_2 \leftrightsquigarrow r_3 \leftrightsquigarrow r_4\)</span>). In the first time step, both agents are in room 1. Every consecutive step, agent <span class="math inline">\(b\)</span> moves one step to the right while agent <span class="math inline">\(a\)</span> remains in room 1. Becuase the Kripke models are not very informative to look at directly, we have at each time step evaluated propositions of form <span class="math inline">\(a_i, \neg a_i, K_{a^\prime} a_i, K_{a^\prime} \neg a_i\)</span> in the distinguished state <span class="math inline">\(s\)</span> (the real world) for every combination of <span class="math inline">\(a \in \{a, b\}, a^\prime \in \{a, b\}, i \in \{1,2,3,4\}\)</span>. The code includes a function for automatically evaluating such a set of propositions and constructing a LaTeXtable that can be used to easily check the state of the Kripke model.</p>
<p>The results are shown in the tables below, where all propositions in the <em>truth</em> row should be read as <span class="math inline">\((\mathbb{M}_t,s_t) \vDash p\)</span>, in the <em>agent a</em> row as <span class="math inline">\((\mathbb{M}_t,s_t) \vDash K_ap\)</span> and in the <em>agent b</em> row as <span class="math inline">\((\mathbb{M}_t,s_t) \vDash K_bp\)</span> (so each table cell shows propositions describing that room that are <em>true</em> or that are <em>known to be true by that agent</em>). <span class="math display">\[\begin{array}{|c|c|c|c|c|}
\hline
t = 1 &amp; \text{Room 1}&amp;\text{Room 2}&amp;\text{Room 3}&amp;\text{Room 4}\\
\hline
\text{Truth} &amp; a_1,b_1 &amp; \neg b_2,\neg a_2 &amp; \neg b_3,\neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\text{Agent a} &amp; a_1,b_1 &amp; \neg b_2,\neg a_2 &amp; \neg b_3,\neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\text{Agent b} &amp; a_1,b_1 &amp; \neg b_2,\neg a_2 &amp; \neg b_3,\neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\end{array}\]</span></p>
<p>Initially, agent <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> can see each other, so both know where the other is, and consequently the entire state of the game.</p>
<p><span class="math display">\[\begin{array}{|c|c|c|c|c|}
\hline
t=2 &amp; \text{Room 1}&amp;\text{Room 2}&amp;\text{Room 3}&amp;\text{Room 4}\\
\hline
\text{Truth} &amp; a_1,\neg b_1 &amp; b_2,\neg a_2 &amp; \neg b_3,\neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\text{Agent a} &amp; a_1,\neg b_1 &amp; b_2,\neg a_2 &amp; \neg b_3,\neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\text{Agent b} &amp; a_1,\neg b_1 &amp; b_2,\neg a_2 &amp; \neg b_3,\neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\end{array}\]</span></p>
<p>At time 2, <span class="math inline">\(b\)</span> has moved one step to the right (as can be read from the <em>truth</em> row). After one step of <span class="math inline">\(b\)</span>, agent <span class="math inline">\(a\)</span> knows that <span class="math inline">\(b\)</span> must be in room 2 because he is no longer in room 1 and this is the only room that was reachable in one step. Similarly, agent <span class="math inline">\(b\)</span> sees that <span class="math inline">\(a\)</span> is not in room 2. Because the only possible actions for <span class="math inline">\(a\)</span> were to move to room 2 or to stay in room 1, he knows <span class="math inline">\(a\)</span> must still be in room 1. Consequently, both agents still know the valuation of all atomic propositions.</p>
<p><span class="math display">\[\begin{array}{|c|c|c|c|c|}
\hline
t = 3 &amp; \text{Room 1}&amp;\text{Room 2}&amp;\text{Room 3}&amp;\text{Room 4}\\
\hline
\text{Truth} &amp; a_1,\neg b_1 &amp; \neg b_2,\neg a_2 &amp; b_3,\neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\text{Agent a} &amp; a_1,\neg b_1 &amp; \neg a_2 &amp; \neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\text{Agent b} &amp; \neg b_1 &amp; \neg b_2 &amp; b_3,\neg a_3 &amp; \neg a_4,\neg b_4\\
\hline
\end{array}\]</span></p>
<p>After another time step, <span class="math inline">\(a\)</span> has no way to know if <span class="math inline">\(b\)</span> stayed in room 2 or moved to room 3. Consequently, all he knows about <span class="math inline">\(b\)</span> is that he is not in room 1 (or he would be seen by <span class="math inline">\(a\)</span>) or in room 4 (because that room cannot be reached from room 1 in two steps). Agent <span class="math inline">\(b\)</span> also doesn’t know exactly where <span class="math inline">\(a\)</span> is anymore, but he does know <span class="math inline">\(a\)</span> cannot be in room 3 or 4.</p>
<p><span class="math display">\[\begin{array}{|c|c|c|c|c|}
\hline
t = 4 &amp; \text{Room 1}&amp;\text{Room 2}&amp;\text{Room 3}&amp;\text{Room 4}\\
\hline
\text{Truth} &amp; a_1,\neg b_1 &amp; \neg b_2,\neg a_2 &amp; \neg b_3,\neg a_3 &amp; b_4,\neg a_4\\
\hline
\text{Agent a} &amp; a_1,\neg b_1 &amp; \neg a_2 &amp; \neg a_3 &amp; \neg a_4\\
\hline
\text{Agent b} &amp; \neg b_1 &amp; \neg b_2 &amp; \neg b_3 &amp; b_4,\neg a_4\\
\hline
\end{array}\]</span></p>
<p>Finally, agent <span class="math inline">\(b\)</span> moves to the last room. Both agents now only kow that the other is not in the same room as they are.</p>
<h1 id="references" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-postconditions">
<p>Benevides, Mario, and Isaque Lima. 2017. “Action Models with Postconditions.” <em>Computacion Y Sistemas</em> 21 (September): 401–6. <a href="https://doi.org/10.13053/CyS-21-3-2808">https://doi.org/10.13053/CyS-21-3-2808</a>.</p>
</div>
<div id="ref-Ditmarsch2007DynamicEL">
<p>Ditmarsch, H. V., W. Hoek, and Barteld P. Kooi. 2007. “Dynamic Epistemic Logic.” In.</p>
</div>
<div id="ref-Bisimulations">
<p>Eijck, Jan van. 2006. “Lecture Notes Logica Voor Ai: Bisimulations.” <a href="https://staff.fnwi.uva.nl/d.j.n.vaneijck2/courses/lai0506/LAI11.pdf">https://staff.fnwi.uva.nl/d.j.n.vaneijck2/courses/lai0506/LAI11.pdf</a>.</p>
</div>
<div id="ref-NetworkX">
<p>Hagberg, Aric A., Daniel A. Schult, and Pieter J. Swart. 2008. “Exploring Network Structure, Dynamics, and Function Using Networkx.” In <em>Proceedings of the 7th Python in Science Conference</em>, edited by Gaël Varoquaux, Travis Vaught, and Jarrod Millman, 11–15. Pasadena, CA USA.</p>
</div>
<div id="ref-partition">
<p>Reid, John. 2007. “Equivalence Partition (Python Recipe).” <a href="https://code.activestate.com/recipes/499354-equivalence-partition/">https://code.activestate.com/recipes/499354-equivalence-partition/</a>.</p>
</div>
</div>
</body>
</html>
